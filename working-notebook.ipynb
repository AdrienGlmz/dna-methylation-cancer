{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Predicting Cancer with DNA Methylation\n",
    "\n",
    "This notebook is a walk-through of our project submitted to the 2020 Hack for Social Good\n",
    " _Build Hackathon.\n",
    "\n",
    "This notebook is organized the following way:\n",
    " 1. Data preparation\n",
    " 2. Preprocessing\n",
    " 3. Model Training and Evaluation\n",
    " 4. Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Environment setup\n",
    "This notebook has been tested with Python 3.8.5. If not done already, create the `DNA_Methylation`\n",
    "virtual environment using conda and the `environment.yml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from google.cloud import bigquery, storage\n",
    "import google.auth\n",
    "\n",
    "from configs import configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We tested this notebook with:\n",
    " - Pandas version used: 1.0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version used: 1.1.2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pandas version used: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Retrieve credentials to use GCP's Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcp-nyc\n"
     ]
    }
   ],
   "source": [
    "credentials, project_id = google.auth.default()\n",
    "print(project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = configs.PROJECT_ID\n",
    "DATASET = configs.DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data preparation\n",
    "\n",
    "In the data preparation part, we will create two bigquery tables that will used to create the\n",
    "final train and test datasets.\n",
    "\n",
    "The first BigQuery table is called `tcga_betas` is a BigQuery partitioned and clustered table\n",
    "that will hold all betas values for all TCGA patients. It will be a table in a long format:\n",
    "one row per betas observation.\n",
    "\n",
    "The second BigQuery table is called `columns_to_keep` is a BigQuery table that will hold the\n",
    "list of CpG site that we will keep in the final dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### First table - `tcga_betas` table: a simple SQL script\n",
    "\n",
    "This first table will be created using a simple SQL query. The query is located in\n",
    "`SQL_queries/tcga_betas.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE dna_cancer_prediction.tcga_betas\n",
      " PARTITION BY RANGE_BUCKET(row_number, GENERATE_ARRAY(1, 11000, 100))\n",
      " CLUSTER BY row_number\n",
      " AS\n",
      " \n",
      " WITH\n",
      "   brca_betas AS (\n",
      "   SELECT\n",
      "     MIM.CpG_probe_id,\n",
      "     dna.case_barcode,\n",
      "     dna.sample_barcode,\n",
      "     dna.probe_id,\n",
      "     dna.beta_value,\n",
      "     gc.Name\n",
      "   FROM\n",
      "     `isb-cgc.platform_reference.methylation_annotation` gc\n",
      "   JOIN\n",
      "     `isb-cgc.TCGA_hg38_data_v0.DNA_Methylation` dna\n",
      "   ON\n",
      "     gc.Name = dna.probe_id\n",
      "   JOIN\n",
      "     `isb-cgc.platform_reference.GDC_hg38_methylation_annotation` MIM\n",
      "   ON\n",
      "     MIM.CpG_probe_id = gc.Name),\n",
      " \n",
      "   participants_id AS (\n",
      "   SELECT\n",
      "     DISTINCT case_barcode\n",
      "   FROM\n",
      "     `isb-cgc.TCGA_hg38_data_v0.DNA_Methylation`),\n",
      " \n",
      "   participants_id_numbered AS (\n",
      "   SELECT\n",
      "     case_barcode,\n",
      "     ROW_NUMBER() OVER (order by case_barcode) as row_number\n",
      "   FROM\n",
      "     participants_id)\n",
      " \n",
      " SELECT\n",
      "   A.case_barcode,\n",
      "   A.beta_value,\n",
      "   A.CpG_probe_id,\n",
      "   A.sample_barcode,\n",
      "   SUBSTR(A.sample_barcode, 14, 2) AS sample_id,\n",
      "   IF\n",
      "   (SUBSTR(A.sample_barcode, 14, 2) IN ('10', '11', '12', '13', '14', '15', '16', '17', '18', '19'), \"normal\",\n",
      "   IF\n",
      "   (SUBSTR(A.sample_barcode, 14, 2) IN ('01', '02', '03', '04',  '05', '06', '07', '08', '09'), 'tumor', \"control\")) AS sample_status,\n",
      "   B.row_number\n",
      " FROM\n",
      "   brca_betas A\n",
      " LEFT JOIN\n",
      "   participants_id_numbered B\n",
      " ON A.case_barcode = B.case_barcode\n"
     ]
    }
   ],
   "source": [
    "SQL_query_path = 'sql_queries/tcga_betas.txt'\n",
    "with open(SQL_query_path, 'r') as f:\n",
    "    sql_query = ' '.join(f.readlines())\n",
    "\n",
    "sql_query = sql_query.replace('__DATASET__', DATASET)\n",
    "sql_query = sql_query.replace('__TABLE_NAME__', 'tcga_betas')\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "TO DO: describe query\n",
    "\n",
    "We can execute the job to create the table in BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "client = bigquery.Client()\n",
    "query_job = client.query(sql_query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Second table - `columns_to_keep`: using dataproc\n",
    "\n",
    "The second table will be created by a Dataflow job. This table will hold the list of CpG sites\n",
    "that will be included in the training dataset.\n",
    "\n",
    "Indeed, we want to keep only the 5,000 best CpG site among the 500,000 that will be able to\n",
    "separate cancerous vs non-cancerous observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!gcloud dataproc jobs submit pyspark --cluster build-hackathon-nyc-cluster \\\n",
    "    --region us-east1 --jars gs://spark-lib/bigquery/spark-bigquery-latest.jar \\\n",
    "    dataproc_processing/create_cpg_sites_list.py \\\n",
    "    -- -gcs_bucket \"build_hackathon_dnanyc_tfx_pipeline\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Creating training dataset\n",
    "\n",
    "We will now use those training tables to create our training dataset. The training dataset will be\n",
    "saved into a GCS bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = configs.DATASET_PATH\n",
    "DATASET_NAME = 'tcga-binary.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def configure_gcs(project_id=PROJECT_ID):\n",
    "    client = storage.Client(project=project_id)\n",
    "    return client\n",
    "\n",
    "def save_to_gcs(df, gcs_path, file_name):\n",
    "    df.to_csv(gcs_path + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def download_from_bigquery(project_id, list_of_columns):\n",
    "    formatted_columns = \"', '\".join(list_of_columns)\n",
    "    query = f\"\"\"\n",
    "    SELECT beta_value, CpG_probe_id, sample_barcode\n",
    "    from `dna_cancer_prediction.tcga_betas`\n",
    "    where CpG_probe_id in ('{formatted_columns}')\n",
    "    \"\"\"\n",
    "    df = pd.read_gbq(query, project_id=project_id)\n",
    "    return df\n",
    "\n",
    "def download_columns_to_keep(project_id):\n",
    "    query = \"\"\"\n",
    "    SELECT CpG_probe_id\n",
    "    from `dna_cancer_prediction.cpg_site_list`\n",
    "    \"\"\"\n",
    "    df = pd.read_gbq(query, project_id=project_id)\n",
    "    return df['CpG_probe_id'].values\n",
    "\n",
    "def merge_and_pivot(df_betas):\n",
    "    # TO DO: use aliquot_barcode instead of sample barcode as identifier\n",
    "    df_betas = df_betas.drop_duplicates(subset=['sample_barcode', 'CpG_probe_id'])\n",
    "    df_p = df_betas.pivot(index=\"sample_barcode\", columns='CpG_probe_id', values='beta_value').reset_index()\n",
    "    df_p['case_barcode'] = df_p['sample_barcode'].str[:12]\n",
    "    df_final = df_p.merge(df_betas[['case_barcode', 'sample_status']],\n",
    "                          how='left', on='case_barcode')\n",
    "    df_final = df_final.drop('case_barcode', axis=1)\n",
    "    df_final = df_final.set_index('sample_barcode')\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gcs_client = configure_gcs(PROJECT_ID)\n",
    "columns = download_columns_to_keep(PROJECT_ID)\n",
    "df = download_from_bigquery(PROJECT_ID, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merge_and_pivot(df)\n",
    "save_to_gcs(df, DATASET_PATH, DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
